dag.overwrite = true
report.overwrite = true
timeline.overwrite = true
trace.overwrite = true

// defaults + workdir,hostname
trace.fields = 'task_id,hash,native_id,name,status,exit,submit,duration,realtime,%cpu,peak_rss,peak_vmem,rchar,wchar,workdir,hostname'

process {
    // Stabilize the output order for all tasks (toward deterministic behavior of the whole pipeline).
    // Also this allows matching tasks by name+(suffix) between pipeline executions for regression-comparisons.
    fair = true
    
    // Use deep (content-hash-based) strategy so that a re-run of an upstream task does not cascade if outputs do not change.
    cache = 'deep'

    // Strict and verbose bash mode; 
    //
    // TODO: Capture detailed time-statistics and force niceness by using
    //      /usr/bin/time --verbose --output=./log/time.log nice -n19 bash
    shell = [ 'bash', '-exuo', 'pipefail' ]

    // TODO: automatically create the following dirs, and refactor tasks to organize the files appropriately.
    // ./tmp - for transient data (e.g. asn-cache, lds-index, etc). Automatically deleted.
    // ./out - for all outputs passed downstream.
    // ./var - auxiliary data that we want to preserve, but not outputs passed to downstream tasks.
    // ./log - logs.
    // beforeScript = 'mkdir -p ./tmp ./out ./var ./log'

    // Remove ./tmp and transient caches upon success (output caches should be placed in ./out)
    // Right now the work-directories are disorganized, so we'll handle the common known cases below.
    //
    // Note that we are not removing lds-directories, e.g. ./LDS_Index ./LDS2 ./lds ./indexed_lds,
    // because they may contain staging symlinks to upstream tasks that we need for post-mortem graph analysis.
    //afterScript  = '[[ -f .exitcode && $(<.exitcode) -eq 0 ]] && rm -rf ./tmp ./interim ./asn_cache ./asncache'
}
