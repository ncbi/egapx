process {
    executor = 'awsbatch'
    // Queue points to a compute environment with a mix of r6i.2xlarge, r6i.4xlarge, and r6i.8xlarge
    // with 200GB EBS gp3 disks, using modified Amazon Linux 2 image with aws cli and docker installed
    // as described in https://www.nextflow.io/docs/latest/aws.html
    queue = 'egapx-small-and-medium-ds'
    // If jobs fail with the message 'out of disk space', create compute environment
    // with r6i.4xlarge instances with 1000GB EBS gp3 disk, connect a queue to it
    // and put the queue name here
    withLabel: 'large_disk' {
        queue = 'egapx-large-disk'
    }
}

aws {
    region = 'us-east-2'
    batch {
        cliPath = '/home/ec2-user/miniconda/bin/aws'
        maxTransferAttempts = 3
    }
    client {
        maxErrorRetry = 3
        socketTimeout = 3600000 // 1 hours in milliseconds
    }
}
